Well before Pandora was a familiar brand name, I first discovered the music genome project when I was a teenager surfing the internet. I thought it was fascinating how they were able to identify elements of music and use that to classify and weave together different types of music. It is an impressive undertaking, but as Johnson identifies in his talk, it is the product of intensive investment from people who are dedicated experts. What Spotify seeks to rely on in determining their music recommendations is a collaborative filtering model, that takes into account the taste of listeners who listen to similar music as the user. 
One thing that is particularly elegant about their approach is how they implicitly determine a user's taste. Instead of relying on ratings from the user, taste can be estimated by whether a track is played or not, weighted by how many times the track is played. Repetition is more expected compared to longer form media such as movies or books, and so frequency can be used an implicit measure of rating. 
Johnson's talk took place at the Spark Summit, which appears to be a conference for the Spark software, which his talk highlights as the way that Spotify is able to carry out their recommendations faster. This is a program that I have no familiarity with, and that section was a bit hard to follow for me due to the unfamiliar terminology. One of the features in Spark that seemed to be particularly helpful was PairRDD functions, which enabled all data to be given key values. I am not sure what he means by partitioners and nodes, but I can understand the basic concept of accessing relevant data easier and faster. I certainly have no experience working on any project whose scale would slow down even the most basic computer, but the scale of Spotify's operation, even a decade ago, necessitates considering processing time.